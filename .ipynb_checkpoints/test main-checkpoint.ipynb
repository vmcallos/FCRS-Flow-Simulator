{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from iapws import IAPWS97\n",
    "import sys\n",
    "#%run equations_module.ipynb\n",
    "%run class_module.ipynb\n",
    "%run equations_v2.ipynb\n",
    "sys.stdout = open(\"simul_log.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import data frame for pipe network;\n",
    "net_df = pd.read_excel('fcrs_in.xls', sheetname=5)#2\n",
    "#import data frame for NODE attributes\n",
    "node_df = pd.read_excel('fcrs_in.xls', sheetname=3)#0\n",
    "#import dataframe for RI pipeline attributes\n",
    "pipe_df = pd.read_excel('fcrs_in.xls', sheetname=4)#1\n",
    "#node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_graph = {}\n",
    "node_dict = {}\n",
    "pipe_dict = {}\n",
    "#Create a graph from nodes; in dictionary format\n",
    "for nodes in range (len(net_df.index)):\n",
    "    nodeID, inlet, outlet, pflow = map(lambda x: net_df.iloc[nodes, x], range(0,4))\n",
    "    #print(nodeID, inlet, outlet, pflow)\n",
    "    network_graph[nodeID] = [inlet, outlet, pflow]\n",
    "\n",
    "for nodes in range(len(node_df.index)):\n",
    "    #create a node class for each row and store it in a dictionary\n",
    "    nodeID,b,c,d,e,f,g,h,i,j,k = map(lambda x: node_df.iloc[nodes, x], range(0,11))\n",
    "    node_dict[nodeID] = node_class(nodeID,b,c,d,e,f,g,h,i,j,k)\n",
    "\n",
    "for pipelines in range(len(pipe_df.index)):\n",
    "    #create a pipeline class for each row and store it in a dictionary\n",
    "    lineID,b,c,d,e,f,g,h,i,j,k  = map(lambda x: pipe_df.iloc[pipelines, x], range(0,11))   \n",
    "    pipe_dict[lineID] = pipe_class(lineID,b,c,d,e,f,g,h,i,j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[print(net, network_graph[net]) for net in sorted(network_graph)]\n",
    "#[print(node_dict[net]) for net in sorted(node_dict)]\n",
    "#[print(pipe_dict[net]) for net in sorted(pipe_dict)]\n",
    "for net in sorted(node_dict):\n",
    "    #print(node_dict[net].p)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate SF and WF after separator vessel\n",
    "sv_out = two_phase()\n",
    "\n",
    "#for sv in sorted(sv_out):\n",
    "#    print(sv, sv_out[sv])\n",
    "sv_link = {'sv3012':['R501', 'S5001'], 'sv3034':['R502', 'S5002'], 'sv3056':['R503', 'S5003'], \\\n",
    "          'sv4012':['R504', 'S5004'], 'sv4034':['R505', 'S5005'], 'sv4050':['R506', 'S5006'], \\\n",
    "          'sv5080':['R508', 'S5008']}\n",
    "#for sv in sorted(sv_link):\n",
    "#    print (node_dict[sv_link[sv][1]].p)#, sv_out[sv][0])\n",
    "\n",
    "for sv in sorted(sv_link):\n",
    "    node_dict[sv_link[sv][0]].p = sv_out[sv][0]\n",
    "    node_dict[sv_link[sv][0]].mf = sv_out[sv][2]\n",
    "    node_dict[sv_link[sv][0]].sio2 = sv_out[sv][3]\n",
    "    node_dict[sv_link[sv][1]].p = sv_out[sv][0]\n",
    "    node_dict[sv_link[sv][1]].mf = sv_out[sv][1]\n",
    "    node_dict[sv_link[sv][1]].co2 = sv_out[sv][4]\n",
    "    node_dict[sv_link[sv][1]].h2s = sv_out[sv][5]\n",
    "    steam = IAPWS97 (P = sv_out[sv][0], x=1)\n",
    "    node_dict[sv_link[sv][0]].t = steam.T-273.15\n",
    "    node_dict[sv_link[sv][1]].t = steam.T-273.15\n",
    "    node_dict[sv_link[sv][0]].calc_ssi()\n",
    "    node_dict[sv_link[sv][1]].calc_ncg()\n",
    "    #print (steam.T-273.15)\n",
    "    #print (node_dict[sv_link[sv][1]].t, node_dict[sv_link[sv][0]].ssi, \\\n",
    "    #       node_dict[sv_link[sv][1]].mf, node_dict[sv_link[sv][1]].co2)\n",
    "    \n",
    "#print (node_dict['R501'].sio2)\n",
    "#node_dict['R501'].calc_ssi()\n",
    "#print (node_dict['R501'].ssi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Create instance of Kf for fittings and insulation params'''\n",
    "kf_list = kf()\n",
    "insul = insulation()\n",
    "\n",
    "\n",
    "for x in sorted(network_graph):\n",
    "    ''' x is the network graph key which is also the pipeID\n",
    "    pipe_dict[x] -> pipeline\n",
    "    network_graph[x][0] -> Inlet Node\n",
    "    network_graph[x][1] -> Outlet Node\n",
    "    '''\n",
    "    '''Calculate Steam T_sat, Rho and Mu from steam table'''\n",
    "    #print(pipe_dict[x], network_graph[x][2])\n",
    "    calc_dp(network_graph[x][0], network_graph[x][1], x, network_graph[x][2])\n",
    "\n",
    "#for node in sorted(node_dict):\n",
    "#    print(node_dict[node].ID, node_dict[node].exergy, node_dict[node].mf, node_dict[node].p)\n",
    "#\n",
    "#for pipe in sorted(pipe_dict):\n",
    "#    print(pipe_dict[pipe].ID, pipe_dict[pipe].Q, pipe_dict[pipe].f_tot, pipe_dict[pipe].f_skin, pipe_dict[pipe].f_fit,\\\n",
    "#         pipe_dict[pipe].udu, pipe_dict[pipe].gdz)\n",
    "for node in sorted(node_dict):\n",
    "    print(node_dict[node].ID,node_dict[node].mf, node_dict[node].co2, node_dict[node].h2s, node_dict[node].t, \\\n",
    "         node_dict[node].p, node_dict[node].exergy)\n",
    "\n",
    "print(\"run OK\")\n",
    "\n",
    "#sample = ['S501X', 'S502X', 'S503X', 'S504X', 'S505X', 'S70IF1', 'S70IF2']\n",
    "\n",
    "#for s in sample:\n",
    "#    print(s, node_dict[s].p, node_dict[s].mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def f_fittings (nf, kf, v):\n",
    "#    v_l = np.full(8,v)\n",
    "#    f_f = nf * kf * v**2 * 0.5\n",
    "#    self.f_fit = sum(f_f)\n",
    "#f_fittings(nf, kf_list, )\n",
    "3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_result = {}\n",
    "\n",
    "for pipe in sorted(pipe_dict):\n",
    "    print(pipe_dict[pipe].ID, pipe_dict[pipe].Q, pipe_dict[pipe].f_tot, pipe_dict[pipe].f_skin, pipe_dict[pipe].f_fit,\\\n",
    "         pipe_dict[pipe].udu, pipe_dict[pipe].gdz, pipe_dict[pipe].h_out, pipe_dict[pipe].t_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
